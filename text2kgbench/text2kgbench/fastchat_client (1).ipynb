{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51387b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Google packages if needed\n",
    "\n",
    "!pip install google\n",
    "!pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0cd0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "from google import genai\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0633eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"C:\\Users\\jguo\\Desktop\\text2kgbench\\\"\n",
    "os.chdir(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b81521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置文件路径\n",
    "input_file = os.path.join(work_dir, \"text2kgbench/text2kgbench/text2kgbench/llm_responses/output_llm_responses_part1.jsonl\")\n",
    "output_cleaned_file = os.path.join(work_dir, \"text2kgbench/text2kgbench/text2kgbench/llm_responses/cleaned_output_llm_responses_part1.jsonl\")\n",
    "output_sampled_file = os.path.join(work_dir, \"text2kgbench/text2kgbench/text2kgbench/text2kgbench/llm_responses/sampled_100_output.jsonl\")\n",
    "\n",
    "# 步骤 1：清洗数据，只保留 response 字段\n",
    "cleaned_data = []\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as fin:\n",
    "    for line in fin:\n",
    "        obj = json.loads(line)\n",
    "        # 如果没有 response 但有 sent，就用 sent 替换 response\n",
    "        response = obj.get(\"response\", obj.get(\"sent\", \"\"))\n",
    "        triples = obj.get(\"triples\", [])\n",
    "        uid = obj.get(\"id\", \"\")\n",
    "        cleaned_data.append({\"id\": uid, \"response\": response, \"triples\": triples})\n",
    "\n",
    "# 保存清洗后的文件\n",
    "with open(output_cleaned_file, 'w', encoding='utf-8') as fout:\n",
    "    for item in cleaned_data:\n",
    "        json.dump(item, fout, ensure_ascii=False)\n",
    "        fout.write('\\n')\n",
    "\n",
    "# 步骤 2：随机抽取 100 条用于评估（你可以改为别的数字）\n",
    "sample_size = 100\n",
    "sampled_data = random.sample(cleaned_data, min(sample_size, len(cleaned_data)))\n",
    "\n",
    "# 保存抽样后的文件\n",
    "with open(output_sampled_file, 'w', encoding='utf-8') as fout:\n",
    "    for item in sampled_data:\n",
    "        json.dump(item, fout, ensure_ascii=False)\n",
    "        fout.write('\\n')\n",
    "\n",
    "print(f\"✅ 已生成 {output_cleaned_file} 和 {output_sampled_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853d127f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4624ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "# 读取CSV\n",
    "df = pd.read_csv('/users/jguo/Desktop/text2kgbench/denominations-emprises-voies-actuelles.csv', dtype=str, sep=';')\n",
    "\n",
    "id_col = \"Identifiant\"\n",
    "denom_col = \"Dénomination complète minuscule\"\n",
    "info_cols = [\"Historique\", \"Dénomination\", \"Classement\", \"Ouverture\", \"Numérotation\"]\n",
    "\n",
    "jsonl_lines = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    exceptions = {\n",
    "        \"dr.\":\"dr\",\n",
    "        \"larg.\":\"larg\",\n",
    "        \"arr. mun.\":\"arr mun\",\n",
    "        \"M.\": \"M\",\n",
    "        \"jan.\" : \"jan\",\n",
    "        \"févr.\": \"févr\",\n",
    "        \"avr.\": \"avr\",\n",
    "        \"juil.\": \"juil\",\n",
    "        \"sept.\": \"sept\",\n",
    "        \"oct.\": \"oct\",\n",
    "        \"nov.\": \"nov\",\n",
    "        \"déc.\": \"déc\",\n",
    "        \"Arr.\":  \"arr\",\n",
    "        \"; place Cabanis ;\":  \", place Cabanis,\",\n",
    "        \". (ponts)\": \" (ponts)\",\n",
    "        \"Ord.\": \"Ord\",\n",
    "        \"préf.\": \"préf\",\n",
    "        \"ord.\": \"ord\",\n",
    "        \"arr.\": \"arr\",\n",
    "        \"(U. P.)\": \"U P\",\n",
    "        \" ; rue Puteaux\": \", rue Puteaux\",\n",
    "        \" L'arr.\": \" L'arr\",\n",
    "        \". mun.\" : \" mun\",\n",
    "        \"(sup.)\": \" (sup)\"\n",
    "      }\n",
    "\n",
    "    identifiant = str(row.get(id_col, '')).strip()\n",
    "    denom = str(row.get(denom_col, '')).strip().lower()\n",
    "    if not identifiant or not denom:\n",
    "        continue  # 跳过无效行\n",
    "\n",
    "    for col in info_cols:\n",
    "        info = str(row.get(col, '')).strip()\n",
    "        if not info or info.lower() in ['nan', 'none']:\n",
    "            continue  # 跳过空内容\n",
    "\n",
    "        # # 多条信息分割\n",
    "        # if ';' in info:\n",
    "        #     infos = [i.strip() for i in info.split(';') if i.strip()]\n",
    "        # elif '\\n' in info:\n",
    "        #     infos = [i.strip() for i in info.split('\\n') if i.strip()]\n",
    "        # else:\n",
    "        #     infos = [info]\n",
    "\n",
    "        # 多条信息分割\n",
    "        \n",
    "        for abbr, full in exceptions.items():\n",
    "            info = info.replace(abbr, full)\n",
    "\n",
    "        # On découpe selon le point \".\", le point virgule \";\" ou le saut de ligne \"\\n\"\n",
    "        infos = re.split(r'[;.\\n]', info)\n",
    "\n",
    "        # On enlève les espaces vides et les chaînes vides\n",
    "        infos = [x.strip() for x in infos if x.strip()]\n",
    "\n",
    "        for i, single_info in enumerate(infos):\n",
    "            if len(infos) == 1:\n",
    "                id_str = f\"{identifiant}_{col.lower()}\"\n",
    "            else:\n",
    "                id_str = f\"{identifiant}_{col.lower()}_{i+1}\"\n",
    "            sent = f\"{denom} || {col} || {single_info}\"\n",
    "            jsonl_lines.append(json.dumps({\"id\": id_str, \"sent\": sent}, ensure_ascii=False))\n",
    "\n",
    "# 写入jsonl文件\n",
    "with open('output.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for line in jsonl_lines:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "print(f\"已生成 {len(jsonl_lines)} 条数据，保存在 output.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e7e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from google import genai\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "dossier_train   = \"/Users/jguo/Desktop/text2kgbench/text2kgbench/text2kgbench/text2kgbench/ground_truth/ground_truth.jsonl\"\n",
    "dossier_test = \"C:/Users/jguo/Desktop/text2kgbench/text2kgbench/text2kgbench/text2kgbench/output.jsonl\"\n",
    "dossier_sortie  = \"/Users/jguo/Desktop/text2kgbench/text2kgbench/text2kgbench/text2kgbench/llm_responses/\"\n",
    "\n",
    "prompt_file = \"/Users/jguo/Desktop/text2kgbench/text2kgbench/text2kgbench/text2kgbench/event_json_to_ttl/prompts/promptSimple.txt\"\n",
    "nom_modele = \"gemini-2.5-pro-preview-05-06\"\n",
    "\n",
    "client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=\"ignf-simv-inference\",\n",
    "    location=\"us-central1\"\n",
    ")\n",
    "\n",
    "os.makedirs(dossier_sortie, exist_ok=True)\n",
    "\n",
    "with open(prompt_file, \"r\", encoding=\"utf-8\") as prompt:\n",
    "    template_prompt = prompt.read()\n",
    "print(template_prompt)\n",
    "\n",
    "def load_train_examples(filepath, max_total=60):\n",
    "    examples = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for ligne in f:\n",
    "            ligne = ligne.strip()\n",
    "            if not ligne or ligne == ',':\n",
    "                continue\n",
    "            if ligne.endswith(','):\n",
    "                ligne = ligne[:-1]\n",
    "            try:\n",
    "                obj = json.loads(ligne)\n",
    "                examples.append(obj)\n",
    "            except Exception as e:\n",
    "                print(\"跳过异常行:\", e, ligne)\n",
    "            if len(examples) >= max_total:\n",
    "                break\n",
    "    return examples\n",
    "\n",
    "def examples_to_prompt_str(exemples):\n",
    "    return \"\\n\\n\".join(json.dumps(ex, ensure_ascii=False) for ex in exemples)\n",
    "\n",
    "def parse_llm_output(raw_output):\n",
    "    import json\n",
    "    import re\n",
    "    # 1. 提取所有```json ... ```块\n",
    "    json_blocks = re.findall(r'```json\\s*(\\{.*?\\})\\s*```', raw_output, re.DOTALL)\n",
    "    results = []\n",
    "    if json_blocks:\n",
    "        for block in json_blocks:\n",
    "            try:\n",
    "                obj = json.loads(block)\n",
    "                results.append(obj)\n",
    "            except Exception as e:\n",
    "                print(\"块解析失败:\", e, block)\n",
    "        return results\n",
    "\n",
    "    # 2. 提取所有裸JSON对象\n",
    "    json_objs = re.findall(r'(\\{(?:[^{}]|(?:\\{[^{}]*\\}))*\\})', raw_output, re.DOTALL)\n",
    "    if json_objs:\n",
    "        for obj_str in json_objs:\n",
    "            try:\n",
    "                obj = json.loads(obj_str)\n",
    "                results.append(obj)\n",
    "            except Exception as e:\n",
    "                print(\"裸对象解析失败:\", e, obj_str)\n",
    "        if results:\n",
    "            return results\n",
    "\n",
    "    # 3. 每行一个JSON对象\n",
    "    lines = [l for l in raw_output.strip().splitlines() if l.strip()]\n",
    "    for l in lines:\n",
    "        print(\"尝试解析行:\", l)\n",
    "        try:\n",
    "            obj = json.loads(l)\n",
    "            results.append(obj)\n",
    "        except Exception as e:\n",
    "            print(\"行解析失败:\", e, l)\n",
    "    if results:\n",
    "        return results\n",
    "\n",
    "    # 4. 整体解析为JSON对象或数组\n",
    "    try:\n",
    "        arr = json.loads(raw_output)\n",
    "        if isinstance(arr, dict):\n",
    "            return [arr]\n",
    "        if isinstance(arr, list):\n",
    "            return arr\n",
    "    except Exception as e:\n",
    "        print(\"整体解析失败:\", e, raw_output)\n",
    "    return []\n",
    "\n",
    "def try_batch(batch, batch_prompt, batch_size, chemin_sortie, i):\n",
    "    print(\"本批次输入ID：\", [rec[\"id\"] for rec in batch])\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=nom_modele,\n",
    "            contents=batch_prompt,\n",
    "        )\n",
    "        raw_output = response.text\n",
    "        print(f\"\\n--- LLM Raw Output for Batch {i} (size={batch_size}) ---\\n{raw_output}\\n--- END ---\\n\")\n",
    "        results = []\n",
    "        try:\n",
    "            results = json.loads(raw_output)\n",
    "            if isinstance(results, dict):\n",
    "                results = [results]\n",
    "        except Exception:\n",
    "            results = parse_llm_output(raw_output)\n",
    "        # 过滤掉None和无id的\n",
    "        results = [parsed for parsed in results if parsed and parsed.get(\"id\")]\n",
    "        print(\"解析后输出ID：\", [parsed.get(\"id\") for parsed in results])\n",
    "        if not results or len(results) < len(batch):\n",
    "            print(f\"⚠️ 批量输出解析失败或条数不足，batch_size={batch_size}，应有{len(batch)}条，实际{len(results)}条，原始内容：\\n\", raw_output)\n",
    "            return False\n",
    "        else:\n",
    "            with open(chemin_sortie, \"a\", encoding=\"utf-8\") as fout:\n",
    "                for parsed in results:\n",
    "                    print(f\"写入: {parsed.get('id', '[NO_ID]')}\")\n",
    "                    fout.write(json.dumps(parsed, ensure_ascii=False) + \"\\n\")\n",
    "            print(f\"✅ Batch {i} ~ {i+len(batch)-1} 已写入 {len(results)} 条 (batch_size={batch_size})\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du traitement du batch {i}-{i+batch_size}: {e}\")\n",
    "        return False\n",
    "\n",
    "# ========== TRAITEMENT PRINCIPAL ==========\n",
    "\n",
    "few_shot_examples = load_train_examples(dossier_train)\n",
    "few_shot_text     = examples_to_prompt_str(few_shot_examples)\n",
    "\n",
    "with open(dossier_test, \"r\", encoding=\"utf-8\") as fin:\n",
    "    records = [json.loads(ligne) for ligne in fin if ligne.strip()]\n",
    "\n",
    "base = os.path.splitext(os.path.basename(dossier_test))[0]\n",
    "i = 0\n",
    "file_idx = 1\n",
    "chemin_sortie = os.path.join(\n",
    "    dossier_sortie, f\"{base}_llm_responses_part{file_idx}.jsonl\"\n",
    ")\n",
    "\n",
    "while i < len(records):\n",
    "    # 每500条切换一个输出文件\n",
    "    if i % 10000 == 0 and i > 0:\n",
    "        print(f\"---- 切换到下一个输出文件 ----\")\n",
    "        file_idx += 1\n",
    "        chemin_sortie = os.path.join(\n",
    "            dossier_sortie, f\"{base}_llm_responses_part{file_idx}.jsonl\"\n",
    "        )\n",
    "\n",
    "    for batch_size in [20,5,1]:\n",
    "        batch = records[i:i+batch_size]\n",
    "        if not batch:\n",
    "            break\n",
    "        batch_prompt = template_prompt + \"\\n\\nExemples :\\n\" + few_shot_text + \"\\n\\n\"\n",
    "        for rec in batch:\n",
    "            batch_prompt += f'Phrase (id={rec[\"id\"]}): {rec[\"sent\"]}\\n'\n",
    "        batch_prompt += \"\\nGénère pour chaque phrase un objet JSON sur une ligne, au format JSONL (une ligne par objet JSON, pas de liste, pas de crochets).\\n\"\n",
    "        token_count = len(batch_prompt) // 4\n",
    "        print(f\"Batch {i} ~ {i+len(batch)-1} (size={batch_size}) 估算token数: {token_count}\")\n",
    "\n",
    "        print(f\"\\n=== Batch {i} ~ {i+len(batch)-1} Prompt (size={batch_size}) ===\\n{batch_prompt}\\n\")\n",
    "       \n",
    "        ok = try_batch(batch, batch_prompt, batch_size, chemin_sortie, i)\n",
    "        if ok:\n",
    "            i += batch_size\n",
    "            break\n",
    "        else:\n",
    "            print(f\"⚠️ Batch size {batch_size} 失败，尝试更小的 batch...\")\n",
    "            time.sleep(2)\n",
    "    else:\n",
    "        # 如果1也失败，则无限重试\n",
    "        print(f\"❌ 连 batch_size=1 都失败，开始无限重试第{i}条数据\")\n",
    "        while True:\n",
    "            batch = records[i:i+1]\n",
    "            batch_prompt = template_prompt + \"\\n\\nExemples :\\n\" + few_shot_text + \"\\n\\n\"\n",
    "            batch_prompt += f'Phrase (id={batch[0][\"id\"]}): {batch[0][\"sent\"]}\\n'\n",
    "            batch_prompt += \"\\nGénère pour chaque phrase un objet JSON sur une ligne, au format JSONL (une ligne par objet JSON, pas de liste, pas de crochets).\\n\"\n",
    "            token_count = len(batch_prompt) // 4\n",
    "            print(f\"重试 Batch {i} (size=1) 估算token数: {token_count}\")\n",
    "            ok = try_batch(batch, batch_prompt, 1, chemin_sortie, i)\n",
    "            if ok:\n",
    "                i += 1\n",
    "                break\n",
    "            else:\n",
    "                print(f\"⚠️ 单条重试失败，3秒后再试...\")\n",
    "                time.sleep(3)\n",
    "\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0af5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设\n",
    "output_ids = ['11815_dénomination', '11815_ouverture', '12621_historique', '9529_historique', '9529_classement', '14371_historique', '9673_historique', '9673_classement', '9673_ouverture', '9673_numérotation', '11703_classement', '11703_ouverture', '9651_dénomination', '9651_ouverture', '14312_historique', '14414_historique', '14494_historique', '14566_historique', '14574_historique', '13914_classement', '12250_historique', '12250_ouverture', '15466_dénomination', '12925_historique', '12925_ouverture', '14037_historique', '14037_classement', '13936_classement', '10518_ouverture', '14561_historique', '11029_historique', '11029_dénomination', '11029_ouverture', '13957_historique', '13957_classement', '12669_historique', '12669_classement', '11306_historique', '11306_ouverture', '12573_historique_1', '12573_historique_2', '12573_dénomination', '12573_numérotation', '11972_historique', '11972_ouverture', '9240_historique', '9240_dénomination', '9240_ouverture', '13902_classement', '13902_ouverture']\n",
    "input_ids = ['11815_dénomination', '11815_ouverture', '12621_historique', '9529_historique', '9529_classement', '14371_historique', '9673_historique', '9673_classement', '9673_ouverture', '9673_numérotation', '11703_classement', '11703_ouverture', '9651_dénomination', '9651_ouverture', '14312_historique', '14414_historique', '14494_historique', '14566_historique', '14574_historique', '13914_classement', '12250_historique', '12250_ouverture', '15466_dénomination', '12925_historique', '12925_ouverture', '14037_historique', '14037_classement', '13936_classement', '10518_ouverture', '14561_historique', '11029_historique', '11029_dénomination', '11029_ouverture', '13957_historique', '13957_classement', '12669_historique', '12669_classement', '11306_historique', '11306_ouverture', '12573_historique_1', '12573_historique_2', '12573_dénomination', '12573_numérotation', '11972_historique', '11972_ouverture', '9240_historique', '9240_dénomination', '9240_ouverture', '13902_classement', '13902_ouverture']\n",
    "\n",
    "missing_ids = [id for id in input_ids if id not in output_ids]\n",
    "print(\"被跳过/遗漏的ID：\", missing_ids)\n",
    "print(\"共遗漏：\", len(missing_ids), \"条\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e43a9ba-0055-4440-a41a-9828d80686c7",
   "metadata": {
    "id": "6e43a9ba-0055-4440-a41a-9828d80686c7"
   },
   "source": [
    "# Generating LLM responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330ff29-7e93-400b-87a1-be18e83f0fba",
   "metadata": {
    "id": "4330ff29-7e93-400b-87a1-be18e83f0fba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = get_llm_response(prompt_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2affabb4-3dc4-44cc-8dcb-a2ae1d26e324",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1746652502326,
     "user": {
      "displayName": "Flora Friedemann",
      "userId": "16883041502599604437"
     },
     "user_tz": -120
    },
    "id": "2affabb4-3dc4-44cc-8dcb-a2ae1d26e324",
    "outputId": "221f664a-6931-47db-8a37-986ee26bd9aa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1cbe6d-f58d-430a-af2f-34aa76797862",
   "metadata": {
    "id": "8d1cbe6d-f58d-430a-af2f-34aa76797862"
   },
   "source": [
    "# Parsing responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bcfc0d-3556-443c-89ba-77323435e263",
   "metadata": {
    "id": "f8bcfc0d-3556-443c-89ba-77323435e263"
   },
   "outputs": [],
   "source": [
    "# go through responses of LLM responses\n",
    "# parse_llm_response(response)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f256a5-edf7-4d4f-94fa-63e84ebb9fdf",
   "metadata": {
    "id": "b7f256a5-edf7-4d4f-94fa-63e84ebb9fdf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "364acb87-7949-4770-9a78-656086c3a567",
   "metadata": {
    "id": "364acb87-7949-4770-9a78-656086c3a567"
   },
   "source": [
    "# Evaluating the triples with the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a6e8b-0a66-45fc-92fd-ec885f4908ca",
   "metadata": {
    "id": "fd3a6e8b-0a66-45fc-92fd-ec885f4908ca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth_files = [\n",
    "    \"onto_1_movie\": \"data/ground_truth/ont_1_movie_ground_truth.jsonl\",\n",
    "    \"onto_2_music\": \"data/ground_truth/ont_1_music_ground_truth.jsonl\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90183521-f98c-41f5-be51-e9fa8eb1d2ef",
   "metadata": {
    "id": "90183521-f98c-41f5-be51-e9fa8eb1d2ef"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "with open(\"/Users/jguo/Desktop/text2kgbench/text2kgbench/text2kgbench/text2kgbench/llm_responses/ont_1_rue_mizon_test_llm_responses.jsonl\",encoding=\"utf-8\") as f:\n",
    "    for i,line in enumerate(f):\n",
    "        rec = json.loads(line)\n",
    "        print(\"id=\", rec[\"id\"], \"; triples=\", rec.get(\"triples\"))\n",
    "        if i>=2: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5245d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.get(\"triples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d4078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/Users/jguo/Desktop/text2kgbench/text2kgbench/text2kgbench/text2kgbench/ground_truth/ont_1_rue_mizon_ground_truth.jsonl\",\"r\",encoding=\"utf-8\") as f:\n",
    "    for i,line in enumerate(f):\n",
    "        rec = json.loads(line)\n",
    "        print(rec[\"id\"], rec.get(\"triples\"))\n",
    "        if i>=2: break\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
